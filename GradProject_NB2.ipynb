{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h1> DS200A Computer Vision Assignment</h1>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h2>  Part Two: Feature Selection </h2>\t\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h4> In this section, we would like you to select between 15 and 20 features to focus your model on. This will require significant explatoratory research. The first one is already implemented for you, and the next two are pre-specified.  </h4>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import anything you need here\n",
    "import os\n",
    "import cv2\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "import matplotlib\n",
    "import skimage\n",
    "from skimage import io\n",
    "from skimage import feature\n",
    "import seaborn as sns\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# load data generated from NB1\n",
    "data = pd.read_hdf(\"data.h5\", \"data\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def convert_to_rgb(image):\n",
    "    \"\"\"\n",
    "    if image is grayscale, convert to RGB\n",
    "    \"\"\"\n",
    "    if(len(image.shape) == 2):\n",
    "        return skimage.color.gray2rgb(image)\n",
    "    else:\n",
    "        return image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data[\"Pictures\"] = data[\"Pictures\"].apply(convert_to_rgb)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_img = data[\"Pictures\"].iloc[0]\n",
    "io.imshow(test_img)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def feature_size(image):\n",
    "    \"\"\"\n",
    "    return picture size\n",
    "    \"\"\"\n",
    "    return image.size\n",
    "\n",
    "def feature_avg_red(image):\n",
    "    \"\"\"\n",
    "    return mean value of red channel\n",
    "    \"\"\"\n",
    "    return image[:, :, 0].mean()\n",
    "\n",
    "def feature_avg_green(image):\n",
    "    \"\"\"\n",
    "    return mean value of green channel  \n",
    "    \"\"\"\n",
    "    return image[:, :, 1].mean()\n",
    "\n",
    "def feature_avg_blue(image):\n",
    "    \"\"\"\n",
    "    return mean value of blue channel\n",
    "    \"\"\"\n",
    "    return image[:, :, 2].mean()\n",
    "\n",
    "def feature_std_red(image):\n",
    "    \"\"\"\n",
    "    return standard derivation of red channel\n",
    "    \"\"\"\n",
    "    return image[:, :, 0].std()\n",
    "\n",
    "def feature_std_green(image):\n",
    "    \"\"\"\n",
    "    return standard derivation of green channel\n",
    "    \"\"\"\n",
    "    return image[:, :, 1].std()\n",
    "\n",
    "def feature_std_blue(image):\n",
    "    \"\"\"\n",
    "    return standard derivation of blue channel\n",
    "    \"\"\"\n",
    "    return image[:, :, 2].std()\n",
    "\n",
    "def feature_avg_gray(image):\n",
    "    \"\"\"\n",
    "    return mean value of grayscale\n",
    "    \"\"\"\n",
    "    return np.mean(image[:, :, 0] + image[:, :, 1] + image[:, :, 2] / 3)\n",
    "\n",
    "def feature_aspect_ratio(image):\n",
    "    \"\"\"\n",
    "    return aspect ratio of the image, \n",
    "    i.e., the height divided by the width of the image\n",
    "    \"\"\"\n",
    "    return image.shape[0] / image.shape[1]\n",
    "\n",
    "def short_side_resize(image, length=256):\n",
    "    \"\"\"\n",
    "    resize the image to a fixed short side length\n",
    "    \"\"\"\n",
    "    height, width, _ = image.shape\n",
    "    if height < width:\n",
    "        ratio = length / height\n",
    "    else:\n",
    "        ratio = length / width\n",
    "    new_height = int(height * ratio)\n",
    "    new_width = int(width * ratio)\n",
    "    return skimage.transform.resize(image, (new_height, new_width), mode='reflect', anti_aliasing=True)\n",
    "\n",
    "def center_crop(image, length=224):\n",
    "    \"\"\"\n",
    "    crop the center patch of the image with length * length\n",
    "    \"\"\"\n",
    "    height, width, _ = image.shape\n",
    "    cx, cy = height // 2, width // 2\n",
    "    lx, ly = cx - length//2, cy - length//2\n",
    "    hx, hy = length + lx, length + ly\n",
    "    return image[lx:hx, ly:hy, :]\n",
    "\n",
    "def feature_harris(image):\n",
    "    \"\"\"\n",
    "    return amount of corners detected by Harris corner detector\n",
    "    \"\"\"\n",
    "    image = center_crop(short_side_resize(image))\n",
    "    gray = skimage.color.rgb2gray(image)\n",
    "    gray = np.array(gray * 255, dtype=np.uint8)\n",
    "    harris = cv2.cornerHarris(gray, blockSize=2, ksize=3, k=0.04)\n",
    "    harris_corners = np.where(harris > 0)\n",
    "    return len(harris_corners[0]) / harris.size\n",
    "\n",
    "def feature_dog(image):\n",
    "    \"\"\"\n",
    "    return the differences of images processed by two Gaussian \n",
    "    filters with different variance (we choose 0.3 and 0.5)\n",
    "    \"\"\"\n",
    "    gray = skimage.color.rgb2gray(image)\n",
    "    g3 = np.asarray(skimage.filters.gaussian(gray, sigma=0.3))\n",
    "    g5 = np.asarray(skimage.filters.gaussian(gray, sigma=0.5))\n",
    "    dog = g3-g5\n",
    "    return sum(sum(dog > 0.05 *dog.max() ))/dog.size\n",
    "\n",
    "def feature_avg_y(image):\n",
    "    \"\"\"\n",
    "    return mean value of luminance Y) \n",
    "    \"\"\"\n",
    "    image = skimage.color.rgb2ycbcr(image)\n",
    "    return image[:, :, 0].mean()\n",
    "\n",
    "def feature_avg_cb(image):\n",
    "    \"\"\"\n",
    "    return mean value of blue chroma component (Cb)\n",
    "    \"\"\"\n",
    "    image = skimage.color.rgb2ycbcr(image)\n",
    "    return image[:, :, 1].mean()\n",
    "\n",
    "def feature_avg_cr(image):\n",
    "    \"\"\"\n",
    "    return mean value of red chroma component (Cr)\n",
    "    \"\"\"\n",
    "    image = skimage.color.rgb2ycbcr(image)\n",
    "    return image[:, :, 2].mean()\n",
    "\n",
    "def feature_std_y(image):\n",
    "    \"\"\"\n",
    "    return standard derivation of luminance (Y)\n",
    "    \"\"\"\n",
    "    image = skimage.color.rgb2ycbcr(image)\n",
    "    return image[:, :, 0].std()\n",
    "\n",
    "def feature_std_cb(image):\n",
    "    \"\"\"\n",
    "    return standard derivation of blue chroma component (Cb)\n",
    "    \"\"\"\n",
    "    image = skimage.color.rgb2ycbcr(image)\n",
    "    return image[:, :, 1].std()\n",
    "\n",
    "def feature_std_cr(image):\n",
    "    \"\"\"\n",
    "    return standard derivation of red chroma component (Cr)\n",
    "    \"\"\"\n",
    "    image = skimage.color.rgb2ycbcr(image)\n",
    "    return image[:, :, 2].std()\n",
    "\n",
    "def feature_avg_hog(image):\n",
    "    \"\"\"\n",
    "    return mean value of Histogram of Oriented Gradients (HOG)\n",
    "    \"\"\"\n",
    "    return skimage.feature.hog(convert_to_rgb(image)).mean()\n",
    "\n",
    "def feature_std_hog(image):\n",
    "    \"\"\"\n",
    "    return standard derivation of Histogram of Oriented Gradients (HOG)\n",
    "    \"\"\"\n",
    "    return skimage.feature.hog(convert_to_rgb(image)).std()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Define more features above, performing any EDA research below. We expect all external sources sited, and a couple significant different graphs indicating some form of EDA. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h4> DataFrame Creation </h4>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def feature_frame(df):\n",
    "    # add all features to a DataFrame and drop `Picture` column\n",
    "    df[\"size\"] = df[\"Pictures\"].apply(feature_size)\n",
    "    df[\"avg_red\"] = df[\"Pictures\"].apply(feature_avg_red)\n",
    "    df[\"avg_green\"] = df[\"Pictures\"].apply(feature_avg_green)\n",
    "    df[\"avg_blue\"] = df[\"Pictures\"].apply(feature_avg_blue)\n",
    "    df[\"std_red\"] = df[\"Pictures\"].apply(feature_std_red)\n",
    "    df[\"std_green\"] = df[\"Pictures\"].apply(feature_std_green)\n",
    "    df[\"std_blue\"] = df[\"Pictures\"].apply(feature_std_blue)\n",
    "    df[\"avg_gray\"] = df[\"Pictures\"].apply(feature_avg_gray)\n",
    "    df[\"aspect_ratio\"] = df[\"Pictures\"].apply(feature_aspect_ratio)\n",
    "    df[\"harris\"] = df[\"Pictures\"].apply(feature_harris)\n",
    "    df[\"dog\"] = df[\"Pictures\"].apply(feature_dog)\n",
    "    df[\"avg_y\"] = df[\"Pictures\"].apply(feature_avg_y)\n",
    "    df[\"avg_cb\"] = df[\"Pictures\"].apply(feature_avg_cb)\n",
    "    df[\"avg_cr\"] = df[\"Pictures\"].apply(feature_avg_cr)\n",
    "    df[\"std_y\"] = df[\"Pictures\"].apply(feature_std_y)\n",
    "    df[\"std_cb\"] = df[\"Pictures\"].apply(feature_std_cb)\n",
    "    df[\"std_cr\"] = df[\"Pictures\"].apply(feature_std_cr)\n",
    "    df[\"avg_hog\"] = df[\"Pictures\"].apply(feature_avg_hog)\n",
    "    df[\"std_hog\"] = df[\"Pictures\"].apply(feature_std_hog)\n",
    "    del df[\"Pictures\"]\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "feature_df = feature_frame(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "feature_df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# storing data to .h5 file for easy loading in NB3\n",
    "feature_df.to_hdf(\"feature.h5\", \"feature\", mode=\"w\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### generate and save feature for validation set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_path = \"20_Validation/\"\n",
    "test_file_list = os.listdir(test_path)\n",
    "    \n",
    "# remove hidden files for macOS system\n",
    "if \".DS_Store\" in test_file_list:\n",
    "    test_file_list.remove(\".DS_Store\")\n",
    "        \n",
    "# sort the directories to match the given encoding\n",
    "test_file_list = sorted(test_file_list, key=lambda x: \n",
    "                        int(x.replace(\"validation_pic (\", \"\").replace(\").jpg\", \"\")))\n",
    "\n",
    "# read images into DataFrame\n",
    "test_image = []\n",
    "for test_file in test_file_list:\n",
    "    test_image.append(io.imread(os.path.join(test_path, test_file)))\n",
    "\n",
    "test_df = pd.DataFrame()\n",
    "test_df[\"Pictures\"] = test_image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_df[\"Pictures\"] = test_df[\"Pictures\"].apply(convert_to_rgb)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_feature = feature_frame(test_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_feature.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_feature.to_hdf(\"test_feature.h5\", \"feature\", mode=\"w\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h4> Graphs </h4>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "category = [\"Airplanes\", \"Bear\", \"Blimp\", \"Comet\", \"Crab\", \"Dog\", \"Dolphin\", \"Giraffe\", \n",
    "            \"Goat\", \"Gorilla\", \"Kangaroo\", \"Killer-Whale\", \"Leopards\", \"Llama\", \n",
    "            \"Penguin\", \"Porcupine\", \"Teddy-Bear,\" \"Triceratops\", \"Unicorn\", \"Zebra\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# use violin plot to visualize each feature's distribution among 20 categories\n",
    "for column in feature_df.columns:\n",
    "    if column != \"Encoding\":\n",
    "        plt.figure(figsize=(12, 9))\n",
    "        sns.violinplot(x=\"Encoding\", y=column, data=feature_df)\n",
    "        plt.title(column)\n",
    "        plt.xticks(range(len(category)), category, rotation='vertical')\n",
    "        plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We find feature `aspect_ratio` and `avg_y` quite interesting on category \"airplanes\" and \"comet\". Further analysis can be found in our report."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h4> Sources </h4>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1. N. Dalal and B. Triggs. Histograms of oriented gradients for human detection. In2005 IEEE ComputerSociety Conference on Computer Vision and Pattern Recognition (CVPR’05), volume 1, pages 886–893vol. 1, June 2005\n",
    "2. Christopher  G.  Harris  and  Mike  Stephens.   A  combined  corner  and  edge  detector.   InAlvey VisionConference, 1988."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
